# test_random_forest.py

import numpy as np
from sklearn.datasets import load_iris, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
# Importa o Random Forest do Sklearn para compara√ß√£o
from sklearn.ensemble import RandomForestClassifier as SklearnRFC
from random_forest_classifier import RandomForestClassifier
from decision_tree_classifier import DecisionTreeClassifier
# Assumindo que voc√™ tem:
# from decision_tree_classifier import DecisionTreeClassifier
# from random_forest import RandomForestClassifier 
# (Se as classes estiverem no mesmo arquivo, voc√™ n√£o precisa destes imports)

# =============================================================
# M√ìDULO DE TESTE: RANDOM FOREST (IRIS Dataset)
# =============================================================

def test_random_forest_classification():
    print("="*15 + " TESTE RANDOM FOREST (IRIS Dataset) " + "="*15)
    
    # 1. Carregar Dados e Dividir
    iris = load_iris()
    X = iris.data
    y = iris.target
    target_names = iris.target_names
    
    # Usamos um random_state para reprodutibilidade
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # ===============================================
    # 2. REFER√äNCIA 1: Sua √Årvore Simples (Base)
    # ===============================================
    print("\n--- üå≤ Refer√™ncia: Sua DecisionTreeClassifier (1 √Årvore) ---")
    
    # Profundidade 3 (onde voc√™ tinha 95.56% antes)
    dtc_base = DecisionTreeClassifier(max_depth=3, criterion='gini')
    dtc_base.fit(X_train, y_train)
    y_pred_base = dtc_base.predict(X_test)
    acc_base = accuracy_score(y_test, y_pred_base)
    
    print(f"Acur√°cia da √Årvore Simples (Manual): {acc_base:.4f}")

    # ===============================================
    # 3. TESTE: Seu RandomForestClassifier
    # ===============================================
    print("\n--- üå≥ Seu RandomForestClassifier (10 √Årvores) ---")
    
    # Par√¢metros: 
    # n_trees=10 (Um n√∫mero pequeno para teste r√°pido)
    # max_features='sqrt' (Padr√£o para RF)
    # max_depth=5 (Permite que as √°rvores cres√ßam um pouco mais, pois o bagging 
    #              ir√° compensar o overfitting de cada √°rvore individual)
    
    rfc_manual = RandomForestClassifier(n_trees=10, max_depth=5, max_features='sqrt')
    rfc_manual.fit(X_train, y_train)
    
    y_pred_manual = rfc_manual.predict(X_test)
    acc_manual = accuracy_score(y_test, y_pred_manual)
    
    print(f"Acur√°cia do Random Forest (Manual): {acc_manual:.4f}")
    print("\nRelat√≥rio de Classifica√ß√£o (Seu C√≥digo):\n")
    print(classification_report(y_test, y_pred_manual, target_names=target_names, zero_division=0))

    # ===============================================
    # 4. REFER√äNCIA 2: Sklearn RandomForestClassifier
    # ===============================================
    print("\n--- üöÄ Sklearn RandomForestClassifier (para valida√ß√£o) ---")
    
    # Sklearn usa max_features='sqrt' por padr√£o e max_depth=None (full growth)
    # Vamos usar os mesmos par√¢metros para compara√ß√£o justa:
    rfc_sklearn = SklearnRFC(n_estimators=10, max_depth=5, max_features='sqrt', random_state=42)
    rfc_sklearn.fit(X_train, y_train)
    
    y_pred_sklearn = rfc_sklearn.predict(X_test)
    acc_sklearn = accuracy_score(y_test, y_pred_sklearn)
    
    print(f"Acur√°cia do Random Forest (Sklearn): {acc_sklearn:.4f}")

    # ===============================================
    # 5. RESUMO
    # ===============================================
    print("\n" + "="*70)
    print("| RESUMO DE ACUR√ÅCIA |")
    print(f"| √Årvore Simples (Manual): {acc_base:.4f} |")
    print(f"| Random Forest (Manual): {acc_manual:.4f} |")
    print(f"| Random Forest (Sklearn): {acc_sklearn:.4f} |")
    print("="*70)

def test_random_forest_breast_cancer():
    print("="*10 + " TESTE RANDOM FOREST (BREAST CANCER) " + "="*10)
    
    # 1. Carregar Dados e Dividir
    data = load_breast_cancer()
    X = data.data
    y = data.target
    target_names = data.target_names # 'malignant' e 'benign'
    
    # Dividir dados (Treino/Teste)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # ===============================================
    # 2. REFER√äNCIA 1: Sua √Årvore Simples (Base)
    # ===============================================
    print("\n--- üå≤ Refer√™ncia: Sua DecisionTreeClassifier (1 √Årvore) ---")
    
    # Permitimos que a √°rvore cres√ßa mais para ver sua acur√°cia m√°xima isolada
    dtc_base = DecisionTreeClassifier(max_depth=None, criterion='gini') 
    dtc_base.fit(X_train, y_train)
    y_pred_base = dtc_base.predict(X_test)
    acc_base = accuracy_score(y_test, y_pred_base)
    
    print(f"Acur√°cia da √Årvore Simples (Manual): {acc_base:.4f}")

    # ===============================================
    # 3. TESTE: Seu RandomForestClassifier
    # ===============================================
    print("\n--- üå≥ Seu RandomForestClassifier (50 √Årvores) ---")
    
    # Aumentamos para 50 √°rvores para um teste mais robusto e pr√≥ximo do real
    # Usamos max_depth=10 e max_features='sqrt'
    rfc_manual = RandomForestClassifier(n_trees=50, max_depth=10, max_features='sqrt')
    
    # O treinamento de 50 √°rvores ser√° visivelmente mais lento, o que √© esperado
    rfc_manual.fit(X_train, y_train) 
    
    y_pred_manual = rfc_manual.predict(X_test)
    acc_manual = accuracy_score(y_test, y_pred_manual)
    
    print(f"Acur√°cia do Random Forest (Manual): {acc_manual:.4f}")
    print("\nRelat√≥rio de Classifica√ß√£o (Seu C√≥digo):\n")
    print(classification_report(y_test, y_pred_manual, target_names=target_names, zero_division=0))

    # ===============================================
    # 4. REFER√äNCIA 2: Sklearn RandomForestClassifier
    # ===============================================
    print("\n--- üöÄ Sklearn RandomForestClassifier (para valida√ß√£o) ---")
    
    rfc_sklearn = SklearnRFC(n_estimators=50, max_depth=10, max_features='sqrt', random_state=42)
    rfc_sklearn.fit(X_train, y_train)
    
    y_pred_sklearn = rfc_sklearn.predict(X_test)
    acc_sklearn = accuracy_score(y_test, y_pred_sklearn)
    
    print(f"Acur√°cia do Random Forest (Sklearn): {acc_sklearn:.4f}")

    # ===============================================
    # 5. RESUMO
    # ===============================================
    print("\n" + "="*70)
    print("| RESUMO DE ACUR√ÅCIA (BREAST CANCER) |")
    print(f"| √Årvore Simples (Manual): {acc_base:.4f} |")
    print(f"| Random Forest (Manual): {acc_manual:.4f} |")
    print(f"| Random Forest (Sklearn): {acc_sklearn:.4f} |")
    print("="*70)

if __name__ == "__main__":
    test_random_forest_classification()
    test_random_forest_breast_cancer()