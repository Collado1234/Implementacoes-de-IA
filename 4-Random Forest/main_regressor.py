# test_regressor.py

import numpy as np
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor as SklearnRFR
# Assumindo que suas classes est√£o import√°veis:
from decision_tree_regressor import DecisionTreeRegressor 
from random_forest_regressor import RandomForestRegressor 
# Se as classes estiverem no mesmo arquivo, remova estes imports.

# =============================================================
# FUN√á√ÉO PRINCIPAL DE TESTE DE REGRESS√ÉO
# =============================================================

def test_random_forest_regressor(ManualDTR, ManualRFR):
    print("="*10 + " TESTE RANDOM FOREST REGRESSOR (DIABETES Dataset) " + "="*10)
    
    # 1. Carregar e Preparar Dados
    data = load_diabetes()
    X, y = data.data, data.target
    
    # Dividir dados (Treino/Teste)
    # N√£o precisamos de StandardScaler aqui, pois √°rvores de decis√£o s√£o robustas a escala
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    # ===============================================
    # 2. REFER√äNCIA 1: Sua √Årvore Simples (Base)
    # ===============================================
    print("\n--- üå≤ Refer√™ncia: Sua DecisionTreeRegressor (1 √Årvore) ---")
    
    # Usamos max_depth=4 (como no seu teste anterior)
    dtr_base = ManualDTR(max_depth=4, criterion='mse')
    
    # A √Årvore de Regress√£o original n√£o usa max_features, ent√£o passamos None
    # NOTA: Se voc√™ ainda n√£o adaptou o DTR para max_features, ele vai ignorar o par√¢metro
    # mas rodar√° se voc√™ passar None ou nada.
    dtr_base.fit(X_train, y_train)
    
    # Predi√ß√µes e M√©tricas
    y_pred_base = dtr_base.predict(X_test)
    mse_base = mean_squared_error(y_test, y_pred_base)
    r2_base = r2_score(y_test, y_pred_base)
    
    print(f"MSE (√Årvore Simples Manual): {mse_base:.2f}")
    print(f"R¬≤ (√Årvore Simples Manual): {r2_base:.4f}")

    # ===============================================
    # 3. TESTE: Seu RandomForestRegressor
    # ===============================================
    print("\n--- üå≥ Seu RandomForestRegressor (20 √Årvores) ---")
    
    # Par√¢metros: n_trees=20 (Bom equil√≠brio) e max_depth=7 (Permitimos mais crescimento)
    # max_features='sqrt' (Padr√£o para RF)
    rfc_manual = ManualRFR(n_trees=20, max_depth=7, max_features='sqrt')
    
    # O treinamento de 20 √°rvores ser√° visivelmente mais lento
    rfc_manual.fit(X_train, y_train) 
    
    # Predi√ß√µes e M√©tricas
    y_pred_manual = rfc_manual.predict(X_test)
    mse_manual = mean_squared_error(y_test, y_pred_manual)
    r2_manual = r2_score(y_test, y_pred_manual)
    
    print(f"MSE (Random Forest Manual): {mse_manual:.2f}")
    print(f"R¬≤ (Random Forest Manual): {r2_manual:.4f}")

    # ===============================================
    # 4. REFER√äNCIA 2: Sklearn RandomForestRegressor
    # ===============================================
    print("\n--- üöÄ Sklearn RandomForestRegressor (para valida√ß√£o) ---")
    
    # Usamos os mesmos par√¢metros para compara√ß√£o justa:
    rfr_sklearn = SklearnRFR(n_estimators=20, max_depth=7, max_features='sqrt', random_state=42)
    rfr_sklearn.fit(X_train, y_train)
    
    # Predi√ß√µes e M√©tricas
    y_pred_sklearn = rfr_sklearn.predict(X_test)
    mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)
    r2_sklearn = r2_score(y_test, y_pred_sklearn)
    
    print(f"MSE (Random Forest Sklearn): {mse_sklearn:.2f}")
    print(f"R¬≤ (Random Forest Sklearn): {r2_sklearn:.4f}")

    # ===============================================
    # 5. RESUMO FINAL
    # ===============================================
    print("\n" + "="*80)
    print(f"| Resumo de Regress√£o (R¬≤) | Base DTR: {r2_base:.4f} | RF Manual: {r2_manual:.4f} | RF Sklearn: {r2_sklearn:.4f} |")
    print("="*80)

# test_regressor.py (Parte final)

if __name__ == "__main__":
    test_random_forest_regressor(DecisionTreeRegressor, RandomForestRegressor) 